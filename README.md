# AnÃ¡lise de VÃ­deo Inteligente

Framework para anÃ¡lise de vÃ­deo com reconhecimento de aÃ§Ãµes humanas, detecÃ§Ã£o facial e anÃ¡lise de emoÃ§Ãµes.

## ğŸ“Œ Funcionalidades Principais

- **Reconhecimento de AÃ§Ãµes Humanas**  
  Identifica atividades em tempo real usando modelo Vision Transformer (ViT)
  - 600+ classes de aÃ§Ãµes humanas
  - SuavizaÃ§Ã£o temporal de prediÃ§Ãµes
  - ExibiÃ§Ã£o de confianÃ§a em tempo real

- **Reconhecimento Facial AvanÃ§ado**
  - DetecÃ§Ã£o de faces com SSD MobileNet
  - Reconhecimento facial com OpenFace
  - Banco de faces conhecidas
  - DetecÃ§Ã£o de emoÃ§Ãµes com DeepFace

- **AnÃ¡lise de EmoÃ§Ãµes**  
  Identifica emoÃ§Ãµes dominantes frame a frame:
  - Alegria, Tristeza, Raiva, Neutro, etc
  - Bounding boxes com labels

## âš™ï¸ PrÃ©-requisitos

- Python 3.8+
- Nvidia GPU (recomendado)
- 4GB+ RAM
- EspaÃ§o em disco: 2GB+

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/GaratujaBR/projeto_analise_video.git
cd projeto_analise_video
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

3. Baixe os modelos necessÃ¡rios:
```python
python -c "from face_recognition import download_models; download_models()"
```

## ğŸ¬ Como Usar

1. Coloque o vÃ­deo de entrada na pasta raiz com o nome `video.mp4`

2. Executar anÃ¡lise de aÃ§Ãµes:
```bash
python detect_activities.py
```

3. Executar reconhecimento facial:
```bash
python face_recognition.py
```

4. AnÃ¡lise de emoÃ§Ãµes:
```bash
python detect_expression_video.py
```

**SaÃ­das Geradas:**
- `output_vit_actions.mp4` - VÃ­deo com aÃ§Ãµes detectadas
- `output_video_enhanced.mp4` - VÃ­deo com reconhecimento facial
- `output_video_emotions.mp4` - VÃ­deo com anÃ¡lise de emoÃ§Ãµes

## ğŸ“‚ Estrutura de Arquivos
```
projeto_analise_video/
â”œâ”€â”€ detect_activities.py       # Reconhecimento de aÃ§Ãµes
â”œâ”€â”€ face_recognition.py        # Reconhecimento facial
â”œâ”€â”€ detect_expression_video.py # AnÃ¡lise de emoÃ§Ãµes
â”œâ”€â”€ images/                    # Faces conhecidas para treino
â”œâ”€â”€ models/                    # Modelos prÃ©-treinados
â””â”€â”€ video.mp4                  # Arquivo de vÃ­deo de entrada
```

## âš¡ ConfiguraÃ§Ã£o
- **Para melhor performance:**  
  Ajuste os parÃ¢metros no cÃ³digo:
  ```python
  # Em detect_activities.py
  self.buffer_size = 5  # Tamanho do buffer de suavizaÃ§Ã£o
  confidence_threshold=0.5  # Limiar de confianÃ§a
  
  # Em face_recognition.py
  self.confidence_threshold = 0.7  # Limiar de detecÃ§Ã£o facial
  ```

## ğŸ’¡ Dicas
- Use vÃ­deos com resoluÃ§Ã£o 720p para melhor performance
- Adicione fotos de rostos conhecidos na pasta `/images`
- Para CPU: reduza o tamanho do buffer nos cÃ³digos

## ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga estes passos:
1. FaÃ§a um fork do projeto
2. Crie sua branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a
MIT License - Consulte o arquivo LICENSE para mais detalhes
```
